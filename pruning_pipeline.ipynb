{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from dataset.fairfd import FairFD\n",
    "from detectors import DETECTOR\n",
    "\n",
    "detector_name = \"spsl\"\n",
    "# detector_name = \"ffd\"\n",
    "args = {\"detector_path\": f\"./config/detector/{detector_name}.yaml\"}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def init_seed(config):\n",
    "    if config['manualSeed'] is None:\n",
    "        config['manualSeed'] = random.randint(1, 10000)\n",
    "    random.seed(config['manualSeed'])\n",
    "    torch.manual_seed(config['manualSeed'])\n",
    "    if config['cuda']:\n",
    "        torch.cuda.manual_seed_all(config['manualSeed'])\n",
    "\n",
    "def prepare_my_testing_data(config, root_path):\n",
    "    paths = [\"data/Asian\", \"data/Caucasian\", \"data/Indian\", \"data/African\"]\n",
    "    test_data_loaders = {}\n",
    "    for i in range(len(paths)):\n",
    "        test_set = FairFD(config, os.path.join(root_path, paths[i]))\n",
    "        test_data_loader = \\\n",
    "            torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=config['test_batchSize'],\n",
    "                shuffle=True,\n",
    "                num_workers=int(config['workers']),\n",
    "                collate_fn=test_set.collate_fn,\n",
    "            )\n",
    "        test_data_loaders[paths[i]] = test_data_loader\n",
    "    return test_data_loaders\n",
    "\n",
    "@torch.no_grad()\n",
    "def inference(model, data_dict):\n",
    "    predictions = model(data_dict, inference=True)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9210c4ef0682e1d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T23:11:29.350975Z",
     "start_time": "2024-08-11T23:11:26.493209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Configuration ---------------\n",
      "Loading data from FairFD ...\n",
      "real: 9688\n",
      "Data from '../dataset/test/data/Asian' loaded.\n",
      "Dataset contains 9688 images.\n",
      "\n",
      "Loading data from FairFD ...\n",
      "real: 10196\n",
      "Data from '../dataset/test/data/Caucasian' loaded.\n",
      "Dataset contains 10196 images.\n",
      "\n",
      "Loading data from FairFD ...\n",
      "real: 10308\n",
      "Data from '../dataset/test/data/Indian' loaded.\n",
      "Dataset contains 10308 images.\n",
      "\n",
      "Loading data from FairFD ...\n",
      "real: 10415\n",
      "Data from '../dataset/test/data/African' loaded.\n",
      "Dataset contains 10415 images.\n",
      "\n",
      "===> Load checkpoint done!\n"
     ]
    }
   ],
   "source": [
    "# parse options and load config\n",
    "with open(args[\"detector_path\"], 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "# print configuration\n",
    "print(\"--------------- Configuration ---------------\")\n",
    "params_string = \"Parameters: \\n\"\n",
    "for key, value in config.items():\n",
    "    params_string += \"{}: {}\".format(key, value) + \"\\n\"\n",
    "# init seed\n",
    "init_seed(config)\n",
    "# set cudnn benchmark if needed\n",
    "if config['cudnn']:\n",
    "    cudnn.benchmark = True\n",
    "# prepare the testing data loaders\n",
    "rootpath = \"../dataset/test\"\n",
    "test_data_loaders = prepare_my_testing_data(config, rootpath)\n",
    "# prepare the model (detector)\n",
    "model_class = DETECTOR[config['model_name']]\n",
    "model = model_class(config).to(device)\n",
    "weights_path = f\"../weights/{detector_name}.pth\"\n",
    "ckpt = torch.load(weights_path, map_location=device)\n",
    "model.load_state_dict(ckpt, strict=True)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "print('===> Load checkpoint done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "187706520299464a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T23:11:32.443643Z",
     "start_time": "2024-08-11T23:11:29.351971Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "filepath1 = os.path.join(\"./saved_activations\", f\"{detector_name}_Caucasian_all_outputs.pkl\")\n",
    "filepath2 = os.path.join(\"./saved_activations\", f\"{detector_name}_Asian_all_outputs.pkl\")\n",
    "filepath3 = os.path.join(\"./saved_activations\", f\"{detector_name}_African_all_outputs.pkl\")\n",
    "filepath4 = os.path.join(\"./saved_activations\", f\"{detector_name}_Indian_all_outputs.pkl\")\n",
    "\n",
    "if os.path.exists(filepath1) and os.path.exists(filepath2) and os.path.exists(filepath3) and os.path.exists(filepath4):\n",
    "    with open(filepath1, 'rb') as f:\n",
    "        Caucasian_all_outputs = pickle.load(f)\n",
    "    with open(filepath2, 'rb') as f:\n",
    "        Asian_all_outputs = pickle.load(f)\n",
    "    with open(filepath3, 'rb') as f:\n",
    "        African_all_outputs = pickle.load(f)\n",
    "    with open(filepath4, 'rb') as f:\n",
    "        Indian_all_outputs = pickle.load(f)\n",
    "else:\n",
    "    outputs = {}\n",
    "    def hook_fn(module, input, output):\n",
    "        class_name = module.__class__.__name__\n",
    "        module_idx = len(outputs)\n",
    "        m_key = f'{class_name}_{module_idx + 1}'\n",
    "        outputs[m_key] = output\n",
    "    \n",
    "    handles = {}\n",
    "    def register_hooks(model):\n",
    "        for module_name, module in model.named_modules():\n",
    "            if isinstance(module, (nn.Conv1d, nn.Conv2d, nn.Conv3d)):\n",
    "                handles[module_name] = module.register_forward_hook(hook_fn)\n",
    "    register_hooks(model)\n",
    "    \n",
    "    Caucasian_all_outputs = {module_name: {'mean': None, 'count': 0} for module_name in handles.keys()}\n",
    "    Asian_all_outputs = {module_name: {'mean': None, 'count': 0} for module_name in handles.keys()}\n",
    "    African_all_outputs = {module_name: {'mean': None, 'count': 0} for module_name in handles.keys()}\n",
    "    Indian_all_outputs = {module_name: {'mean': None, 'count': 0} for module_name in handles.keys()}\n",
    "    \n",
    "    for test_loader_name, test_loader in test_data_loaders.items():\n",
    "        with torch.no_grad():\n",
    "            for data_dict in tqdm(test_loader):\n",
    "                data_dict['image'], data_dict['label'] = data_dict['image'].to(device), data_dict['label'].to(device)\n",
    "                temp_output = model(data_dict)\n",
    "                \n",
    "                if \"Caucasian\" in test_loader_name:\n",
    "                    for module_name, key in zip(Caucasian_all_outputs.keys(), outputs.keys()):\n",
    "                        temp_data = outputs[key].cpu().detach().numpy()\n",
    "                        if Caucasian_all_outputs[module_name]['mean'] is None:\n",
    "                            Caucasian_all_outputs[module_name]['mean'] = np.mean(temp_data, axis=0)\n",
    "                            Caucasian_all_outputs[module_name]['count'] += temp_data.shape[0]\n",
    "                        else:\n",
    "                            old_mean = Caucasian_all_outputs[module_name]['mean']\n",
    "                            count = Caucasian_all_outputs[module_name]['count']\n",
    "                            new_count = temp_data.shape[0]\n",
    "                            new_mean = ((count * old_mean) + np.sum(temp_data, axis=0)) / (count + new_count)\n",
    "                            Caucasian_all_outputs[module_name]['mean'] = new_mean\n",
    "                            Caucasian_all_outputs[module_name]['count'] += new_count\n",
    "                elif \"Asian\" in test_loader_name:\n",
    "                    for module_name, key in zip(Asian_all_outputs.keys(), outputs.keys()):\n",
    "                        temp_data = outputs[key].cpu().detach().numpy()\n",
    "                        if Asian_all_outputs[module_name]['mean'] is None:\n",
    "                            Asian_all_outputs[module_name]['mean'] = np.mean(temp_data, axis=0)\n",
    "                            Asian_all_outputs[module_name]['count'] += temp_data.shape[0]\n",
    "                        else:\n",
    "                            old_mean = Asian_all_outputs[module_name]['mean']\n",
    "                            count = Asian_all_outputs[module_name]['count']\n",
    "                            new_count = temp_data.shape[0]\n",
    "                            new_mean = ((count * old_mean) + np.sum(temp_data, axis=0)) / (count + new_count)\n",
    "                            Asian_all_outputs[module_name]['mean'] = new_mean\n",
    "                            Asian_all_outputs[module_name]['count'] += new_count\n",
    "                elif \"African\" in test_loader_name:\n",
    "                    for module_name, key in zip(African_all_outputs.keys(), outputs.keys()):\n",
    "                        temp_data = outputs[key].cpu().detach().numpy()\n",
    "                        if African_all_outputs[module_name]['mean'] is None:\n",
    "                            African_all_outputs[module_name]['mean'] = np.mean(temp_data, axis=0)\n",
    "                            African_all_outputs[module_name]['count'] += temp_data.shape[0]\n",
    "                        else:\n",
    "                            old_mean = African_all_outputs[module_name]['mean']\n",
    "                            count = African_all_outputs[module_name]['count']\n",
    "                            new_count = temp_data.shape[0]\n",
    "                            new_mean = ((count * old_mean) + np.sum(temp_data, axis=0)) / (count + new_count)\n",
    "                            African_all_outputs[module_name]['mean'] = new_mean\n",
    "                            African_all_outputs[module_name]['count'] += new_count\n",
    "                elif \"Indian\" in test_loader_name:\n",
    "                    for module_name, key in zip(Indian_all_outputs.keys(), outputs.keys()):\n",
    "                        temp_data = outputs[key].cpu().detach().numpy()\n",
    "                        if Indian_all_outputs[module_name]['mean'] is None:\n",
    "                            Indian_all_outputs[module_name]['mean'] = np.mean(temp_data, axis=0)\n",
    "                            Indian_all_outputs[module_name]['count'] += temp_data.shape[0]\n",
    "                        else:\n",
    "                            old_mean = Indian_all_outputs[module_name]['mean']\n",
    "                            count = Indian_all_outputs[module_name]['count']\n",
    "                            new_count = temp_data.shape[0]\n",
    "                            new_mean = ((count * old_mean) + np.sum(temp_data, axis=0)) / (count + new_count)\n",
    "                            Indian_all_outputs[module_name]['mean'] = new_mean\n",
    "                            Indian_all_outputs[module_name]['count'] += new_count\n",
    "                else:\n",
    "                    print(\"No such race\")\n",
    "                    exit(1)\n",
    "                # Clear Hook Output\n",
    "                outputs = {}\n",
    "                \n",
    "    for module_name, _ in handles.items():\n",
    "        handles[module_name].remove()\n",
    "        \n",
    "    with open(filepath1, 'wb') as f:\n",
    "        pickle.dump(Caucasian_all_outputs, f)\n",
    "    with open(filepath2, 'wb') as f:\n",
    "        pickle.dump(Asian_all_outputs, f)\n",
    "    with open(filepath3, 'wb') as f:\n",
    "        pickle.dump(African_all_outputs, f)\n",
    "    with open(filepath4, 'wb') as f:\n",
    "        pickle.dump(Indian_all_outputs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4160db304a2cedf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T23:11:32.634582Z",
     "start_time": "2024-08-11T23:11:32.446142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: backbone.adjust_channel.0\n",
      "Success: backbone.conv1.weight torch.Size([32, 4, 3, 3])\n",
      "Success: backbone.conv2.weight torch.Size([64, 32, 3, 3])\n",
      "Error:The size of tensor a (128) must match the size of tensor b (64) at non-singleton dimension 0 backbone.block1.skip.weight torch.Size([128, 64, 1, 1])\n",
      "Error:The size of tensor a (64) must match the size of tensor b (128) at non-singleton dimension 0 backbone.block1.rep.0.conv1.weight torch.Size([64, 1, 3, 3])\n",
      "Success: backbone.block1.rep.0.pointwise.weight torch.Size([128, 64, 1, 1])\n",
      "Success: backbone.block1.rep.3.conv1.weight torch.Size([128, 1, 3, 3])\n",
      "Success: backbone.block1.rep.3.pointwise.weight torch.Size([128, 128, 1, 1])\n",
      "Error:The size of tensor a (256) must match the size of tensor b (128) at non-singleton dimension 0 backbone.block2.skip.weight torch.Size([256, 128, 1, 1])\n",
      "Error:The size of tensor a (128) must match the size of tensor b (256) at non-singleton dimension 0 backbone.block2.rep.1.conv1.weight torch.Size([128, 1, 3, 3])\n",
      "Success: backbone.block2.rep.1.pointwise.weight torch.Size([256, 128, 1, 1])\n",
      "Success: backbone.block2.rep.4.conv1.weight torch.Size([256, 1, 3, 3])\n",
      "Success: backbone.block2.rep.4.pointwise.weight torch.Size([256, 256, 1, 1])\n",
      "Error:The size of tensor a (728) must match the size of tensor b (256) at non-singleton dimension 0 backbone.block3.skip.weight torch.Size([728, 256, 1, 1])\n",
      "Error:The size of tensor a (256) must match the size of tensor b (728) at non-singleton dimension 0 backbone.block3.rep.1.conv1.weight torch.Size([256, 1, 3, 3])\n",
      "Success: backbone.block3.rep.1.pointwise.weight torch.Size([728, 256, 1, 1])\n",
      "Success: backbone.block3.rep.4.conv1.weight torch.Size([728, 1, 3, 3])\n",
      "Success: backbone.block3.rep.4.pointwise.weight torch.Size([728, 728, 1, 1])\n",
      "Success: backbone.block4.rep.1.conv1.weight torch.Size([728, 1, 3, 3])\n",
      "Success: backbone.block4.rep.1.pointwise.weight torch.Size([728, 728, 1, 1])\n",
      "Success: backbone.block4.rep.4.conv1.weight torch.Size([728, 1, 3, 3])\n",
      "Success: backbone.block4.rep.4.pointwise.weight torch.Size([728, 728, 1, 1])\n",
      "Success: backbone.block4.rep.7.conv1.weight torch.Size([728, 1, 3, 3])\n",
      "Success: backbone.block4.rep.7.pointwise.weight torch.Size([728, 728, 1, 1])\n",
      "Success: backbone.block5.rep.1.conv1.weight torch.Size([728, 1, 3, 3])\n",
      "Success: backbone.block5.rep.1.pointwise.weight torch.Size([728, 728, 1, 1])\n",
      "Success: backbone.block5.rep.4.conv1.weight torch.Size([728, 1, 3, 3])\n",
      "Success: backbone.block5.rep.4.pointwise.weight torch.Size([728, 728, 1, 1])\n",
      "Success: backbone.block5.rep.7.conv1.weight torch.Size([728, 1, 3, 3])\n",
      "Success: backbone.block5.rep.7.pointwise.weight torch.Size([728, 728, 1, 1])\n",
      "Success: backbone.block6.rep.1.conv1.weight torch.Size([728, 1, 3, 3])\n",
      "Success: backbone.block6.rep.1.pointwise.weight torch.Size([728, 728, 1, 1])\n",
      "Success: backbone.block6.rep.4.conv1.weight torch.Size([728, 1, 3, 3])\n",
      "Success: backbone.block6.rep.4.pointwise.weight torch.Size([728, 728, 1, 1])\n",
      "Success: backbone.block6.rep.7.conv1.weight torch.Size([728, 1, 3, 3])\n",
      "Success: backbone.block6.rep.7.pointwise.weight torch.Size([728, 728, 1, 1])\n",
      "Success: backbone.block7.rep.1.conv1.weight torch.Size([728, 1, 3, 3])\n",
      "Success: backbone.block7.rep.1.pointwise.weight torch.Size([728, 728, 1, 1])\n",
      "Success: backbone.block7.rep.4.conv1.weight torch.Size([728, 1, 3, 3])\n",
      "Success: backbone.block7.rep.4.pointwise.weight torch.Size([728, 728, 1, 1])\n",
      "Success: backbone.block7.rep.7.conv1.weight torch.Size([728, 1, 3, 3])\n",
      "Success: backbone.block7.rep.7.pointwise.weight torch.Size([728, 728, 1, 1])\n",
      "Success: backbone.block8.rep.1.conv1.weight torch.Size([728, 1, 3, 3])\n",
      "Success: backbone.block8.rep.1.pointwise.weight torch.Size([728, 728, 1, 1])\n",
      "Success: backbone.block8.rep.4.conv1.weight torch.Size([728, 1, 3, 3])\n",
      "Success: backbone.block8.rep.4.pointwise.weight torch.Size([728, 728, 1, 1])\n",
      "Success: backbone.block8.rep.7.conv1.weight torch.Size([728, 1, 3, 3])\n",
      "Success: backbone.block8.rep.7.pointwise.weight torch.Size([728, 728, 1, 1])\n",
      "Success: backbone.block9.rep.1.conv1.weight torch.Size([728, 1, 3, 3])\n",
      "Success: backbone.block9.rep.1.pointwise.weight torch.Size([728, 728, 1, 1])\n",
      "Success: backbone.block9.rep.4.conv1.weight torch.Size([728, 1, 3, 3])\n",
      "Success: backbone.block9.rep.4.pointwise.weight torch.Size([728, 728, 1, 1])\n",
      "Success: backbone.block9.rep.7.conv1.weight torch.Size([728, 1, 3, 3])\n",
      "Success: backbone.block9.rep.7.pointwise.weight torch.Size([728, 728, 1, 1])\n",
      "Success: backbone.block10.rep.1.conv1.weight torch.Size([728, 1, 3, 3])\n",
      "Success: backbone.block10.rep.1.pointwise.weight torch.Size([728, 728, 1, 1])\n",
      "Success: backbone.block10.rep.4.conv1.weight torch.Size([728, 1, 3, 3])\n",
      "Success: backbone.block10.rep.4.pointwise.weight torch.Size([728, 728, 1, 1])\n",
      "Success: backbone.block10.rep.7.conv1.weight torch.Size([728, 1, 3, 3])\n",
      "Success: backbone.block10.rep.7.pointwise.weight torch.Size([728, 728, 1, 1])\n",
      "Success: backbone.block11.rep.1.conv1.weight torch.Size([728, 1, 3, 3])\n",
      "Success: backbone.block11.rep.1.pointwise.weight torch.Size([728, 728, 1, 1])\n",
      "Success: backbone.block11.rep.4.conv1.weight torch.Size([728, 1, 3, 3])\n",
      "Success: backbone.block11.rep.4.pointwise.weight torch.Size([728, 728, 1, 1])\n",
      "Success: backbone.block11.rep.7.conv1.weight torch.Size([728, 1, 3, 3])\n",
      "Success: backbone.block11.rep.7.pointwise.weight torch.Size([728, 728, 1, 1])\n",
      "Error:The size of tensor a (1024) must match the size of tensor b (728) at non-singleton dimension 0 backbone.block12.skip.weight torch.Size([1024, 728, 1, 1])\n",
      "Success: backbone.block12.rep.1.conv1.weight torch.Size([728, 1, 3, 3])\n",
      "Success: backbone.block12.rep.1.pointwise.weight torch.Size([728, 728, 1, 1])\n",
      "Error:The size of tensor a (728) must match the size of tensor b (1024) at non-singleton dimension 0 backbone.block12.rep.4.conv1.weight torch.Size([728, 1, 3, 3])\n",
      "Success: backbone.block12.rep.4.pointwise.weight torch.Size([1024, 728, 1, 1])\n",
      "Success: backbone.conv3.conv1.weight torch.Size([1024, 1, 3, 3])\n",
      "Success: backbone.conv3.pointwise.weight torch.Size([1536, 1024, 1, 1])\n",
      "Success: backbone.conv4.conv1.weight torch.Size([1536, 1, 3, 3])\n",
      "Success: backbone.conv4.pointwise.weight torch.Size([2048, 1536, 1, 1])\n",
      "Error:expected np.ndarray (got float) backbone.adjust_channel.0.weight torch.Size([512, 2048, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# method = \"weight\"\n",
    "# method = \"activation\"\n",
    "method = \"weight_activation\"\n",
    "\n",
    "importance_scores = {}\n",
    "for key in Caucasian_all_outputs.keys():\n",
    "    try:\n",
    "        arrays = [Caucasian_all_outputs[key]['mean'], Asian_all_outputs[key]['mean'], African_all_outputs[key]['mean'], Indian_all_outputs[key]['mean']]\n",
    "        l2_norms = [np.linalg.norm(arr, axis=(1, 2)) for arr in arrays]\n",
    "        l2_norms_stacked = np.stack(l2_norms, axis=-1)\n",
    "        std_l2_norms = np.std(l2_norms_stacked, axis=1)\n",
    "        importance_scores[key] = std_l2_norms\n",
    "    except:\n",
    "        print(\"Error:\", key)\n",
    "        importance_scores[key] = 0.0000000001\n",
    "\n",
    "detector_path = args[\"detector_path\"]\n",
    "with open(detector_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "model_weights = torch.load(f\"../weights/{detector_name}.pth\", map_location=device)\n",
    "\n",
    "absolute_product = {}\n",
    "for key in model_weights.keys():\n",
    "    try:\n",
    "        if key in [onekey+\".weight\" for onekey in importance_scores.keys()]:\n",
    "            if method == \"weight\":\n",
    "                abs_product = torch.abs(model_weights[key]).to(device)\n",
    "            elif method == \"activation\":\n",
    "                abs_product = torch.ones_like(model_weights[key]) / torch.abs(torch.from_numpy(importance_scores[key[:-len(\".weight\")]])).view(-1, 1, 1, 1).to(device)\n",
    "            elif method == \"weight_activation\":\n",
    "                abs_product = torch.abs(model_weights[key]) / torch.abs(torch.from_numpy(importance_scores[key[:-len(\".weight\")]])).view(-1, 1, 1, 1).to(device)\n",
    "            else:\n",
    "                print(\"No this method!\")\n",
    "                break\n",
    "            \n",
    "            absolute_product[key] = abs_product\n",
    "            print(f\"Success:\", key, model_weights[key].shape)\n",
    "    except Exception as e:\n",
    "        print(f\"Error:{e}\", key, torch.abs(model_weights[key]).shape)\n",
    "importance_scores = absolute_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5782b93497b75a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "pruning_fraction = 0.001\n",
    "model_class = DETECTOR[config['model_name']]\n",
    "model = model_class(config)\n",
    "model_weights = torch.load(f\"../weights/{detector_name}.pth\", map_location=device)\n",
    "model.load_state_dict(model_weights)\n",
    "\n",
    "pruned_state_dict = model.state_dict()\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, (nn.Conv2d, nn.Linear, nn.Conv1d)):\n",
    "        try:\n",
    "            weight = module.weight.data\n",
    "            score = importance_scores[name + '.weight']\n",
    "            assert weight.shape == score.shape, f\"Shape mismatch for {name}: weight {weight.shape}, score {score.shape}\"\n",
    "            num_params = weight.numel()\n",
    "            num_to_prune = int(pruning_fraction * num_params)\n",
    "            _, indices = torch.topk(score.view(-1), num_to_prune, largest=False)\n",
    "            mask = torch.ones_like(weight).view(-1)\n",
    "            mask[indices] = 0\n",
    "            mask = mask.view(weight.shape)\n",
    "            pruned_weight = weight * mask\n",
    "            module.weight.data.copy_(pruned_weight)\n",
    "            pruned_state_dict[name + '.weight'] = pruned_weight\n",
    "            print(f\"Pruned {name}: {num_to_prune} out of {num_params} parameters\")\n",
    "        except Exception as e:\n",
    "            print(f\"No Pruned {name}\", e)\n",
    "torch.save(pruned_state_dict, f\"../weights/{detector_name}_prun.pth\")\n",
    "\n",
    "# Run test code\n",
    "# detector_path = f\"./config/detector/{detector_name}.yaml\"\n",
    "# weights_path = f\"../weights/{detector_name}_prun.pth\"\n",
    "# !CUDA_VISIBLE_DEVICES=0 python test-get-confidence.py --detector_path={detector_path} --weights_path={weights_path}\n",
    "\n",
    "# # Clear Jupyter Output\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571db1dca94f1c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d0bcc0238eb388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b013540bd434aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb7dcfbfa4b7812",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
